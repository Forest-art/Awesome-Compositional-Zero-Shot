# Awesome-Compositional-Zero-Shot

Papers and codes about Compositional Zero Shot Learning(CZSL) for computer vision are present on this page. Besides, the commonly-used datasets for CZSL are also introduced. 

##  Papers

### 2022
| Title                                                                                      |   Venue   |              Dataset              |                                                                              PDF                                                                               |                      CODE                      |
|:------------------------------------------------------------------------------------------ |:---------:|:---------------------------------:|:--------------------------------------------------------------------------------------------------------------------------------------------------------------:|:----------------------------------------------:|
| A Decomposable Causal View of Compositional Zero-Shot Learning                             | TMM 2022  |      MIT-States & UT-Zappos       |                                              [PDF](https://ieeexplore.ieee.org/document/9864072/metrics#metrics)                                               |   [CODE](https://github.com/muliyangm/DeCa)    |
| KG-SP: Knowledge Guided Simple Primitives for Open World Compositional Zero-Shot Learning  | CVPR 2022 |  MIT-States & UT-Zappos & C-GQA   |                                                            [PDF]( http://arxiv.org/pdf/2205.06784)                                                             | [CODE](https://github.com/explainableml/kg-sp) |
| Disentangling Visual Embeddings for Attributes and Objects                                 | CVPR 2022 | MIT-States & UT-Zappos & VAW-CZSL |                                                          [PDF](https://arxiv.org/pdf/2205.08536.pdf)                                                           |   [CODE](https://github.com/nirat1606/oadis)   |
| Siamese Contrastive Embedding Network for Compositional Zero-Shot Learning                 | CVPR 2022 |  MIT-States & UT-Zappos & C-GQA   | [PDF](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Siamese_Contrastive_Embedding_Network_for_Compositional_Zero-Shot_Learning_CVPR_2022_paper.pdf) | [CODE](https://github.com/XDUxyLi/SCEN-master) |
| On Leveraging Variational Graph Embeddings for Open World Compositional Zero-Shot Learning |   arXiv   |  MIT-States & UT-Zappos & C-GQA   | [PDF](https://arxiv.org/abs/2204.11848) | -  |
| 3D Compositional Zero-shot Learning with DeCompositional Consensus | ECCV 2022 | C-PartNet  | [PDF](https://arxiv.org/pdf/2111.14673.pdf)|    [CODE](https://github.com/ferjad/3DCZSL)    |
| Learning Graph Embeddings for Open World Compositional Zero-Shot Learning |TPAMI 2022| MIT-States & UT-Zappos & C-GQA | [PDF](https://arxiv.org/pdf/2105.01017)| - |


### 2021
| Title                                                                                 |    Venue     |            Dataset             |                                                                          PDF                                                                          |                        CODE                        |
|:------------------------------------------------------------------------------------- |:------------:|:------------------------------:|:-----------------------------------------------------------------------------------------------------------------------------------------------------:|:--------------------------------------------------:|
| Learning Graph Embeddings for Compositional Zero-Shot Learning                        |  CVPR 2021   | MIT-States & UT-Zappos & C-GQA | [PDF](https://openaccess.thecvf.com/content/CVPR2021/papers/Naeem_Learning_Graph_Embeddings_for_Compositional_Zero-Shot_Learning_CVPR_2021_paper.pdf) |   [CODE](https://github.com/ExplainableML/czsl)    |
| Relation-aware Compositional Zero-shot Learning for Attribute-Object Pair Recognition |  CVPR 2021   |     MIT-States & UT-Zappos     |                                        [PDF](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9513585)                                        | [CODE](https://github.com/daoyuan98/Relation-CZSL) |
| Open World Compositional Zero-Shot Learning                                           |  CVPR 2021   |     MIT-States & UT-Zappos     |                                        [PDF](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9578210)                                        |   [CODE](https://github.com/ExplainableML/czsl)    |
| Independent Prototype Propagation for Zero-Shot Compositionality                      | NeurIPS 2021 |      AO-Clevr & UT-Zappos      |                                                      [PDF](https://arxiv.org/pdf/2106.00305.pdf)                                                      |   [CODE](https://github.com/FrankRuis/ProtoProp)   |
| Learning Single/Multi-Attribute of Object with Symmetry and Group                     |  TPAMI 2021  |     MIT-States & UT-Zappos     |                                                        [PDF](https://arxiv.org/pdf/2110.04603)                                                        |  [CODE](https://github.com/DirtyHarryLYL/SymNet)   |
|Relation-aware Compositional Zero-shot Learning for Attribute-Object Pair Recognition | TMM 2021 | MIT-States & UT-Zappos | [PDF](https://arxiv.org/pdf/2108.04603) | [CODE](https://github.com/daoyuan98/Relation-CZSL) |
 


### 2020
| Title                                                                   |    Venue     |        Dataset         |                                                                   PDF                                                                    |                           CODE                            |
|:----------------------------------------------------------------------- |:------------:|:----------------------:|:----------------------------------------------------------------------------------------------------------------------------------------:|:---------------------------------------------------------:|
| Symmetry and Group in Attribute-Object Compositions                     |  CVPR 2020   | MIT-States & UT-Zappos | [PDF](https://openaccess.thecvf.com/content_CVPR_2020/papers/Li_Symmetry_and_Group_in_Attribute-Object_Compositions_CVPR_2020_paper.pdf) |      [CODE](https://github.com/DirtyHarryLYL/SymNet)      |
| Learning Unseen Concepts via Hierarchical Decomposition and Composition |  CVPR 2020   | MIT-States & UT-Zappos |                                 [PDF](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9156655)                                  |                             -                             |
| A causal view of compositional zero-shot recognition                    | NeurIPS 2020 |  UT-Zappos & AO-Clevr  |                         [PDF](https://papers.nips.cc/paper/2020/file/1010cedf85f6a7e24b087e63235dc12e-Paper.pdf)                         | [CODE](https://github.com/nv-research-israel/causal_comp) |


### 2019
| Title                                                                                 |   Venue   |        Dataset         |                                                                PDF                                                                |                            CODE                             |
|:------------------------------------------------------------------------------------- |:---------:|:----------------------:|:---------------------------------------------------------------------------------------------------------------------------------:|:-----------------------------------------------------------:|
| Adversarial Fine-Grained Composition Learning for Unseen Attribute-Object Recognition | ICCV 2019 | MIT-States & UT-Zappos | [PDF](https://see.xidian.edu.cn/faculty/chdeng/Welcome%20to%20Cheng%20Deng's%20Homepage_files/Papers/Conference/ICCV2019_Kun.pdf) |                              -                              |
| Task-Driven Modular Networks for Zero-Shot Compositional Learning                     | ICCV 2019 | MIT-States & UT-Zappos |                                        [PDF](https://ieeexplore.ieee.org/document/9010265)                                        | [CODE](https://github.com/facebookresearch/taskmodularnets) |
| Recognizing Unseen Attribute-Object Pair with Generative Model | AAAI 2019 | MIT-States & UT-Zappos | [PDF](https://ojs.aaai.org/index.php/AAAI/article/view/4907) | - |



### 2018
| Title                                                                                 |   Venue   |        Dataset         |                                                                PDF                                                                | CODE |
|:------------------------------------------------------------------------------------- |:---------:|:----------------------:|:---------------------------------------------------------------------------------------------------------------------------------:|:----:|
| Attributes as Operators: Factorizing Unseen Attribute-Object Compositions | CVPR 2018 | MIT-States & UT-Zappos  | [PDF](https://arxiv.org/pdf/1803.09851.pdf) | [CODE](https://github.com/Tushar-N/attributes-as-operators) |

### 2017
| Title                                                                                 |   Venue   |        Dataset         |                                                                PDF                                                                | CODE |
|:------------------------------------------------------------------------------------- |:---------:|:----------------------:|:---------------------------------------------------------------------------------------------------------------------------------:|:----:|
| From Red Wine to Red Tomato: Composition with Context | CVPR 2017 | MIT-States & UT-Zappos  | [PDF](https://ieeexplore.ieee.org/document/8099612) | [CODE](https://github.com/imisra/composing_cvpr17) |




##  Datasets

Most CZSL papers usually conduct experiments on MIT-States and UT-Zappos datasets. However, as CZSL receives more attention, some new datasets are proposed and used in recent papers, such as C-GQA, AO-CLEVr, etc.

### MIT-States

Introduced by Isola et al. in  [Discovering States and Transformations in Image Collections](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7298744).

The MIT-States dataset has 245 object classes, 115 attribute classes and ∼53K images. There is a wide range of objects (e.g., fish, persimmon, room) and attributes (e.g., mossy, deflated, dirty). On average, each object instance is modified by one of the 9 attributes it affords.

Source:http://web.mit.edu/phillipi/Public/states_and_transformations/index.html

### UT-Zappos

Introduced by Yu et al. in [Fine-Grained Visual Comparisons with Local Learning](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6909426).

UT Zappos50K (UT-Zap50K) is a large shoe dataset consisting of 50,025 catalog images collected from  [Zappos.com](https://www.zappos.com/). The images are divided into 4 major categories — shoes, sandals, slippers, and boots — followed by functional types and individual brands. The shoes are centered on a white background and pictured in the same orientation for convenient analysis.

Source:https://vision.cs.utexas.edu/projects/finegrained/utzap50k/

### C-GQA

Introduced by Muhammad et al. in [Learning Graph Embeddings for Compositional Zero-shot Learning](https://openaccess.thecvf.com/content/CVPR2021/papers/Naeem_Learning_Graph_Embeddings_for_Compositional_Zero-Shot_Learning_CVPR_2021_paper.pdf).

Compositional GQA (C-GQA) dataset is curated from the recent Stanford [GQA](https://cs.stanford.edu/people/dorarad/gqa/) dataset originally proposed for VQA.  C-GQA includes 453 attribute classes and 870 object classes, contains over 9.5k compositional labels with diverse compositional classes and clean annotations, making it the most extensive dataset for CZSL.

Source:https://github.com/ExplainableML/czsl

### AO-CLEVr

Introduced by Atzmon et al. in [A causal view of compositional zero-shot recognition](https://proceedings.neurips.cc/paper/2020/hash/1010cedf85f6a7e24b087e63235dc12e-Abstract.html).

AO-CLEVr is a new synthetic-images dataset containing images of "easy" Attribute-Object categories, based on the CLEVr. AO-CLEVr has attribute-object pairs created from 8 attributes: { red, purple, yellow, blue, green, cyan, gray, brown } and 3 object shapes {sphere, cube, cylinder}, yielding 24 attribute-object pairs. Each pair consists of 7500 images. Each image has a single object that consists of the attribute-object pair. The object is randomly assigned one of two sizes (small/large), one of two materials (rubber/metallic), a random position, and random lightning according to CLEVr defaults.

Source:https://github.com/nv-research-israel/causal_comp

### VAW-CZSL

Introduced by Nirat Saini et al. in [Disentangling Visual Embeddings for Attributes and Objects](https://arxiv.org/pdf/2205.08536.pdf).

VAW-CZSL, a subset of VAW, which is a multilabel attribute-object dataset. Sample one attribute per image, leading to much larger dataset in comparison to previous datasets. The images in the VAW dataset come from the [Visual Genome dataset](https://visualgenome.org/) which is also the source of the images in the [GQA](https://cs.stanford.edu/people/dorarad/gqa/about.html) and the [VG-Phrasecut](https://github.com/ChenyunWu/PhraseCutDataset) datasets.

Source:https://github.com/nirat1606/OADis.

### Compositional PartNet

Introduced by Muhammad et al. in [3D Compositional Zero-shot Learning with DeCompositional Consensus](https://arxiv.org/pdf/2111.14673).

Compositional PartNet (C-PartNet) is refined from [PartNet](https://partnet.cs.stanford.edu) with a new labeling scheme that relates the compositional knowledge between objects by merging and renaming the repeated labels. The relabelled C-PartNet consists of 96 parts compared to 128 distinct part labels in the original PartNet.

Source:https://github.com/ferjad/3DCZSL

##  Acknowledgements
This page is made by [Yanyi Zhang](https://github.com/Yanyi-Zhang) and [Jianghao Li](https://github.com/liccoco), both of whom are graduate students of Dalian University of Technology and supervised by Prof.[Yu Liu](https://liuyudut.github.io) and Prof.[Qi Jia](http://faculty.dlut.edu.cn/guqi/zh_CN/index.htm).